{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_scale(val, new_range, pd_series):\n",
    "    '''\n",
    "    Function will scale element of pandas series to new range\n",
    "    \n",
    "    arg1 (int)    : value\n",
    "    arg2 (list)  : [Min, Max]\n",
    "    arg3 (series) : Pandas series to apply function to\n",
    "    \n",
    "    Return: the new scaled valued\n",
    "    '''\n",
    "    s_range = [pd_series.min(),pd_series.max()]\n",
    "    return round(np.diff(new_range)[0] * ((val - s_range[0])/(np.diff(s_range)[0])) + 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Centering\n",
    "\n",
    "def mean_center_rows(df):\n",
    "    '''\n",
    "    Function to center a dataset based on mean\n",
    "    \n",
    "    arg1 (df): Dataframe\n",
    "    '''\n",
    "    return (df.T - df.mean(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new_user_rating():\n",
    "    '''\n",
    "    Function to generate 5 sample titles from subset titles\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Pull in datasets\n",
    "    with pd.HDFStore('datasets/movie.hdf5') as store:\n",
    "        rt = store['subset_title_ids']\n",
    "        titles = store['titles_series']\n",
    "\n",
    "    # Randomly genreate 5 titles for user to rate\n",
    "    sampling_title_list = random.sample(rt.to_list(),5)\n",
    "    \n",
    "    # Filter dataframe\n",
    "    st_df = titles.loc[sampling_title_list,:]\n",
    "    \n",
    "    # Rename index header name\n",
    "    st_df.index.name = 'title_id'\n",
    "    \n",
    "    st_df.reset_index(inplace=True)\n",
    "    \n",
    "    return st_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please rate the following 5 titles with comma: ['real genius', 'the long', 'embrace of the vampire', 'friday the 13th: part 6: jason lives', 'best of the best'] 5,3,2,1,4\n"
     ]
    }
   ],
   "source": [
    "# Ask for user input and convert input into a list\n",
    "sample_df = gen_new_user_rating()\n",
    "sample_titles = sample_df['title'].to_list()\n",
    "\n",
    "user_rate = input(f'Please rate the following 5 titles with comma: {sample_titles}')\n",
    "user_rate = [int(x) for x in user_rate.split(\",\")]\n",
    "\n",
    "# Create a user_dict from title and user's input\n",
    "user_res = dict(zip(sample_df['title_id'],user_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7483: 5, 8511: 3, 11908: 2, 15362: 1, 6372: 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_closest_user(user_res, user_res_loc, users_df_name, users_loc):\n",
    "    '''\n",
    "    Function to find next closest user\n",
    "    '''\n",
    "    with pd.HDFStore(users_loc) as store:\n",
    "        users = store[users_df_name]\n",
    "    \n",
    "    # Create a user series with index as -1 and append to user-title matrix\n",
    "    to_append = pd.Series(data=user_res, index=user_res,name=-1)\n",
    "    \n",
    "    # Make a copy so as not to contiminate original dataframe; append to user-title matrix\n",
    "    user1 = users.copy()\n",
    "    user1 = user1[list(user_res.keys())]\n",
    "    user1 = user1.append(to_append)\n",
    "    \n",
    "    # Drop users that have no ratings for the chosen nth titles\n",
    "    user1 = user1[list(user_res.keys())].dropna(axis=0, how='all')\n",
    "\n",
    "        # Mean Centering the ratings\n",
    "    user1_mc = mean_center_rows(user1)\n",
    "    user1_mc = user1_mc.fillna(0)\n",
    "\n",
    "    # Create User sim matrix\n",
    "    user1_sim = cosine_similarity(user1_mc)\n",
    "    user1_sim = pd.DataFrame(user1_sim, columns=user1_mc.index, index = user1_mc.index)\n",
    "\n",
    "    # Find the next most similar user to user other than user\n",
    "    next_sim = user1_sim[[-1]].sort_values(by=-1, ascending=False).iloc[1].name\n",
    "\n",
    "    return next_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2152273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "next_user = find_next_closest_user(user_res, \"\",'users','datasets/movie.hdf5')\n",
    "next_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_rec(hdf5_loc, user_id, top_rec=5):\n",
    "    '''\n",
    "    Function will put the following stored dataframe/series from HDF5, series must be in the same name: \n",
    "    1. users         => dataframe containing the user/title utility Matrix\n",
    "    2. user_sim      => dataframe containing the user cosine similiarity matrix\n",
    "    3. titles_series => Series of title and movie_id\n",
    "    \n",
    "    Arguments\n",
    "    arg1 (str) : HDF5 File location\n",
    "    arg2 (int) : User_id\n",
    "    arg3 (int) : Top nth number of recommendation\n",
    "    \n",
    "    retun:\n",
    "    DataFrame with movie_id, title, composite score\n",
    "    '''\n",
    "    \n",
    "    # Import user rating file\n",
    "    with pd.HDFStore(hdf5_loc) as store:\n",
    "        users_sim = store['users_sim']\n",
    "        users = store['users']\n",
    "        index_title_dict = store['titles_series'].to_dict()['title']\n",
    "    \n",
    "    # Find user's similarity scores against users have positive similarity\n",
    "    users_sim = users_sim[user_id].drop(user_id)\n",
    "    users_sim = users_sim[users_sim > 0]\n",
    "    \n",
    "    # Convert user's score to weight; A 1-D array of weights\n",
    "    user_weight = users_sim.values/np.sum(users_sim.values)\n",
    "    \n",
    "    # Find title ratings of titles which user has not rate; A 2-D array of ratings bounded by user-unwatch titles & users that are similar\n",
    "    titles_rating = users.T\n",
    "    titles_rating = titles_rating[titles_rating[user_id].isnull()]\n",
    "    titles_rating = titles_rating.drop(user_id, axis=1)\n",
    "    titles_rating = titles_rating[users_sim.index]\n",
    "    \n",
    "    # Find the score of titles which user has not rate; A 1-D array of composite ratings\n",
    "    user_rating = np.dot(titles_rating.fillna(0).values, user_weight)\n",
    "    \n",
    "    # convert to a dataframe\n",
    "    user_rec_df = pd.DataFrame(user_rating, index=titles_rating.index,\n",
    "                               columns=['composite_rating']).sort_values(by='composite_rating', ascending=False).head(top_rec)\n",
    "    \n",
    "    # reset index to get movie_id as 1 of the column\n",
    "    user_rec_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Map to find the title\n",
    "    user_rec_df['title'] = user_rec_df['movie_id'].map(index_title_dict)\n",
    "    user_rec_df = user_rec_df[['movie_id', 'title','composite_rating']]\n",
    "    user_rec_df.rename({'movie_id':'title_id'}, axis=1, inplace=True)\n",
    "    \n",
    "    # Apply Standard Rating Scaling\n",
    "    user_rec_df['composite_rating'] = user_rec_df['composite_rating'].apply(common_scale, args=([1,5],user_rec_df['composite_rating']))\n",
    "    \n",
    "    # Return a dataframe of the titles recommendation\n",
    "    return user_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>title</th>\n",
       "      <th>composite_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6037</td>\n",
       "      <td>the bourne identity</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2372</td>\n",
       "      <td>the bourne supremacy</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3605</td>\n",
       "      <td>the wizard of oz: collector's edition</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>571</td>\n",
       "      <td>american beauty</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1180</td>\n",
       "      <td>a beautiful mind</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_id                                  title  composite_rating\n",
       "0      6037                    the bourne identity              5.00\n",
       "1      2372                   the bourne supremacy              2.51\n",
       "2      3605  the wizard of oz: collector's edition              1.98\n",
       "3       571                        american beauty              1.62\n",
       "4      1180                       a beautiful mind              1.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cf_rec('datasets/movie.hdf5', next_user, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Based Recommendation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_weighter(users_df, title_sim, movies_sim, user_id, title_id):\n",
    "    \n",
    "    '''\n",
    "    Function: Return the title name and its weights to other similar title\n",
    "    \n",
    "    '''\n",
    "    title_sim = movies_sim[title_id].drop(title_id)\n",
    "    title_sim = title_sim[title_sim > 0]\n",
    "        \n",
    "    # Find the weight of each title similarity\n",
    "    title_weights = title_sim.values/np.sum(title_sim.values)\n",
    "\n",
    "    # Filter by title similarity then but those that have user's rating\n",
    "    user_ratings = users_df.T[user_id].loc[title_sim.index].fillna(0)\n",
    "\n",
    "    # Find the composite rating of the single unwatch title\n",
    "    return (title_id, np.dot(user_ratings.values, title_weights))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_based_recommender(hdf5_loc, user_res, user_id, top_rec=5):\n",
    "    '''\n",
    "    Function\n",
    "    \n",
    "    '''\n",
    "    # Top_rec dataframe containers\n",
    "    chunks = []\n",
    "    \n",
    "    # Import user rating file\n",
    "    with pd.HDFStore(hdf5_loc) as store:\n",
    "        movies_sim = store['movies_sim']\n",
    "        users = store['users']\n",
    "        index_title_dict = store['titles_series'].to_dict()['title']\n",
    "\n",
    "    # Loop through user_response\n",
    "    for mv_id, rating in user_res.items():\n",
    "        \n",
    "        # Find list of titles that are positively similar to the title\n",
    "        title_sim = movies_sim[mv_id].drop(mv_id)\n",
    "        title_sim = title_sim[title_sim > 0]\n",
    "        \n",
    "        # create a list of titles to iterate \n",
    "        n_watch = list(title_sim.sort_values(ascending=False).head(20).index)\n",
    "        \n",
    "        # Return a list of recommendation for each title that user have not watch\n",
    "        ls_rec = [title_weighter(users, title_sim, movies_sim, user_id, title) for title in n_watch]\n",
    "                        \n",
    "        # Create a dataframe of recommendations\n",
    "        com_rec_df = pd.DataFrame(data=ls_rec, columns=['movie_id', 'composite_rating']).sort_values(by='composite_rating', ascending=False).head(top_rec)\n",
    "        \n",
    "        # Apply User's rating weight\n",
    "        com_rec_df['composite_rating'] = com_rec_df['composite_rating'] * rating/len(user_res)\n",
    "        \n",
    "        # Append to rec_df container\n",
    "        chunks.append(com_rec_df)\n",
    "    \n",
    "    # Concat dataframe together\n",
    "    user_rec_df = pd.concat(chunks,ignore_index=True)\n",
    "    \n",
    "    # Map to find the title\n",
    "    user_rec_df['title'] = user_rec_df['movie_id'].map(index_title_dict)\n",
    "    user_rec_df = user_rec_df[['movie_id', 'title','composite_rating']]\n",
    "    user_rec_df.rename({'movie_id':'title_id'}, axis=1, inplace=True)\n",
    "    \n",
    "    # Apply standard scaling\n",
    "    user_rec_df['composite_rating'] = user_rec_df['composite_rating'].apply(common_scale, args=([1,5],user_rec_df['composite_rating']))\n",
    "    \n",
    "    # Sort & Remove Duplicates\n",
    "    user_rec_df.sort_values(by='composite_rating', ascending=False, inplace=True)\n",
    "    user_rec_df.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "    \n",
    "    # Return a dataframe of the titles recommendation\n",
    "    return user_rec_df.head(top_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.77 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>title</th>\n",
       "      <th>composite_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>705</td>\n",
       "      <td>major league</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6716</td>\n",
       "      <td>spies like us</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10212</td>\n",
       "      <td>weird science</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7779</td>\n",
       "      <td>willow</td>\n",
       "      <td>4.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4761</td>\n",
       "      <td>the cannonball run</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_id               title  composite_rating\n",
       "0       705        major league              5.00\n",
       "1      6716       spies like us              4.94\n",
       "2     10212       weird science              4.93\n",
       "3      7779              willow              4.91\n",
       "4      4761  the cannonball run              4.89"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "title_based_recommender('datasets/movie.hdf5', user_res,next_user, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style= 'color:magenta'>Remark:</span>\n",
    "Comparing the results from both Collaborative Filtering RS & Item-Based RS, the recommendated list seems similar. This may indicate that most system are able to identify quite similarily what the user wants OR it could be that the sampled user has a very skewed watch-list eg. only watch a particular genre and nothing else hence resulting in similar recommendation. I will be creating a Neural Network Content-Based RS and see if we can get similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Keyword Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(name, n = 10):\n",
    "    \"\"\"Find n most similar items (or least) to name based on embeddings. Option to also plot the results\"\"\"\n",
    "    \n",
    "    \n",
    "    # Retrieve pre-calculated title weights\n",
    "    with h5py.File('datasets/movie_NN.hdf5','r') as hf:\n",
    "        weights = hf['title_weights'][:]\n",
    "        \n",
    "    with pd.HDFStore('datasets/movie.hdf5') as store:\n",
    "        idx_t_ids_dict = store['idx_title_series'].to_dict()\n",
    "        index_title_dict = store['titles_series'].to_dict()['title']\n",
    "    \n",
    "    t_ids_idx_dict = {item : key for key,item in idx_t_ids_dict.items()}\n",
    "    \n",
    "    # Create a list container to hold calculated dictionary\n",
    "    ls_of_dicts = []\n",
    "    \n",
    "    # Select index and reverse index\n",
    "    index_name = 'title'\n",
    "    index = t_ids_idx_dict\n",
    "    rindex = idx_t_ids_dict\n",
    "\n",
    "    # Check to make sure `name` is in index\n",
    "    try:\n",
    "        # Calculate dot product between book and all others\n",
    "        dists = np.dot(weights, weights[index[name]])\n",
    "    except KeyError:\n",
    "        print(f'{name} Not Found.')\n",
    "        return\n",
    "    \n",
    "    # Sort distance indexes from smallest to largest\n",
    "    sorted_dists = np.argsort(dists)\n",
    "    \n",
    "    # Take the last n sorted distances; remove the title itself\n",
    "    closest = sorted_dists[-(n+1):][:-1]\n",
    "    \n",
    "    ls_of_dicts = [{'title': rindex[c], 'composite_rating': dists[c]} for c in reversed(closest)]\n",
    "    \n",
    "    user_rec_df = pd.DataFrame(ls_of_dicts)\n",
    "    \n",
    "    # Map title name to title id\n",
    "    user_rec_df['title'] = user_rec_df['title'].map(index_title_dict)\n",
    "    \n",
    "    return user_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_based_recommender(user_res, top_rec=10):\n",
    "    '''\n",
    "    Function to run rec algorithms \n",
    "    \n",
    "    '''\n",
    "    chunks = []\n",
    "    for mv_id, rating in user_res.items():\n",
    "        df = find_similar(mv_id, n = 10)\n",
    "        \n",
    "        # Apply weights based on user's rating\n",
    "        df['composite_rating'] = df['composite_rating'] * rating/len(user_res)\n",
    "        \n",
    "        # Append dataframe\n",
    "        chunks.append(df)\n",
    "\n",
    "    # Concat dataframe together\n",
    "    user_rec_df = pd.concat(chunks,ignore_index=True)\n",
    "    \n",
    "    # Apply standard scaling\n",
    "    user_rec_df['composite_rating'] = user_rec_df['composite_rating'].apply(common_scale, args=([1,5],user_rec_df['composite_rating']))\n",
    "    \n",
    "    user_rec_df.sort_values(by='composite_rating', ascending=False, inplace=True)\n",
    "    user_rec_df.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "    user_rec_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return user_rec_df.head(top_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>composite_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>play it to the bone</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bobby jones</td>\n",
       "      <td>4.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shaolin soccer</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the best of times</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rookie of the year</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title  composite_rating\n",
       "0  play it to the bone              5.00\n",
       "1          bobby jones              4.91\n",
       "2       shaolin soccer              4.85\n",
       "3    the best of times              4.84\n",
       "4   rookie of the year              4.80"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_based_recommender(user_res, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Recommendation based on popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe in movie.hdf5 <KeysViewHDF5 ['genre_series', 'idx_title_series', 'keywords_series', 'movies_sim', 'subset_title_ids', 'titles_series', 'users', 'users_sim']>\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('datasets/movie.hdf5','r')\n",
    "print(f'Dataframe in movie.hdf5 {hf.keys()}')\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe in movie.hdf5 <KeysViewHDF5 ['full_ratings', 'titles_cleaned', 'titles_search_mvid']>\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('datasets/movie_raw.hdf5','r')\n",
    "print(f'Dataframe in movie.hdf5 {hf.keys()}')\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import rating datafile\n",
    "with pd.HDFStore('datasets/movie_raw.hdf5') as store:\n",
    "    ratings = store['full_ratings']\n",
    "\n",
    "# Import subset_title_ids\n",
    "with pd.HDFStore('datasets/movie.hdf5') as store:\n",
    "    rt = store['subset_title_ids']\n",
    "    sub_title = store['titles_series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1    16\n",
       "2    17\n",
       "3    18\n",
       "4    26\n",
       "dtype: int16"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  rating       date  movie_id\n",
       "0      1488844       3 2005-09-06         1\n",
       "1       822109       5 2005-05-13         1\n",
       "2       885013       4 2005-10-19         1\n",
       "3        30878       4 2005-12-26         1\n",
       "4       823519       3 2004-05-03         1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>1025579</td>\n",
       "      <td>4</td>\n",
       "      <td>2003-03-29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>712664</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-02-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>1331154</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-07-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2632461</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-07-22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>44937</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-06-22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id  rating       date  movie_id\n",
       "692      1025579       4 2003-03-29         3\n",
       "693       712664       5 2004-02-01         3\n",
       "694      1331154       4 2004-07-03         3\n",
       "695      2632461       3 2005-07-22         3\n",
       "696        44937       5 2004-06-22         3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find ratings for titles that are in my subset\n",
    "ratings = ratings[ratings['movie_id'].isin(rt)]\n",
    "\n",
    "# Find titles in subsets that have ratings >= 3\n",
    "ratings = ratings[ratings['rating'] >=3]\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find the count of positive ratings for each movie\n",
    "ratings_series = ratings.groupby('movie_id')['customer_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1786</td>\n",
       "      <td>character</td>\n",
       "      <td>[History, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2030</td>\n",
       "      <td>screamers</td>\n",
       "      <td>[Horror, Science Fiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>4843</td>\n",
       "      <td>7 seconds</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>9830</td>\n",
       "      <td>immortal beloved</td>\n",
       "      <td>[Drama, Music, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>3645</td>\n",
       "      <td>never die alone</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_id  num_ratings             title                             genre\n",
       "0         3         1786         character                  [History, Drama]\n",
       "1        16         2030         screamers         [Horror, Science Fiction]\n",
       "2        17         4843         7 seconds         [Action, Crime, Thriller]\n",
       "3        18         9830  immortal beloved           [Drama, Music, Romance]\n",
       "4        26         3645   never die alone  [Action, Crime, Drama, Thriller]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe of the popular titles\n",
    "popular_titles = pd.DataFrame(ratings_series).reset_index().rename({'movie_id': 'title_id', 'customer_id':'num_ratings'}, axis=1)\n",
    "\n",
    "# merge popular titles with additional information\n",
    "popular_titles = pd.merge(popular_titles, sub_title, how='inner',left_on='title_id', right_on='movie_id')\n",
    "popular_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "From the above, we can see that all recommendations systems provide different titles based on different aspect of the understanding the user. An ensemble model was created to find the best title recommendation from each of the sub-recommendating system. This will give a more generalized titles recommendations to user. \n",
    "\n",
    "Comparing to the the base recommendations - popularity titles, we see that our recommendations systems pushes titles that are more relating to the user's preference. In addition to this, the systems in its entirety has achieved to eliminate cold start problem where new users may be recommended something that are not to their taste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "Limitation of data available. Initially API-calls to MovieDB was supposed to be the panacea to the limited information available. However, MoiveDB do not have an exact match function but give the best movie hence I have to discards some of my data. In total, I have to reduce close to about 16% of my data.\n",
    "\n",
    "The traditional machine learning models based recommendation systems - Collaborative Filtering and Title-Based are computationally expensive. This limits me to use a subset in order to generate the user matrix. Hence the recommendations may not be as comprehensive in terms of the titles to push to users. In additional, for every user, it need to re-calculate the user matrix again hence reducing the user experience when they need to wait longer time to find titles that are suitable to their taste.\n",
    "\n",
    "*Neural Network (Meta-data rec system) although eliminate the problems experienced by traditional ML but it suffers from longer training time when we runs more epochs and more embedded layers. However, it do not suffers the long calculation time required to generate recommendations to users.\n",
    "\n",
    "Each systems have their pros and cons and the bottlenecks occurs at different sections. However, storing preference is for Neutral Networks because:\n",
    "- Heavy lifting is during the model training phase hence the on the user-front, there is close to little lag in pushing titles to users.\n",
    "- Additional of inputs/variables are an additional layers into the Neural Network. It is relative easier to perform features \"top-up\" compared to traditional MLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Given the short turn-around time, evaluation of the recommendation system is limited to referencing to the popular titles in the database. The next steps is to explore deeper into evaluation metrics using confusion matrix metric to find how each system are recommending titles correctly using created training datasets (created as part of training for neural network)\n",
    "\n",
    "Another direction is to look into TDIDF of meta-data. This will give a aggregated weight matrix of meta-data across all the titles. Using this matrix in the Neural Network might give better recommendation as it takes into account of weight of each keyword the title contains. Currently, each keywords is assumed to have the same weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
